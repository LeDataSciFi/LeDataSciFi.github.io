
## General guidelines

### [Guidelines for assignments](guidelines-asgn.html)

Read this before you start doing any assignments!

### [Guidelines for peer review](guidelines-peerreview.html)

Read this before you start doing any peer review!

## Assignments and project

All relevant delivery dates are on the [schedule](https://ledatascifi.github.io/#schedule). In addition to the deliverables below, there are peer reviews you'll be delivering as well. 

### [ASGN01 - Our tools](asgn01.html)

Using GitHub, writing in Markdown, managing a repo with GitHub and GitHub Desktop, and basic Python coding in Jupyter.

### [ASGN02 - Golden rules in practice, with pandas](asgn02.html)

We will explore a dataset using the `pandas` package, push our programming toolkit further, and practice good habits.

### [ASGN03 - Data viz](asgn03.html)

Tables are decent for understanding data and conveying trends and relationships, but figures are often much better. 

### [ASGN04 - Merging data and munging data](asgn04.html)

More often than not, you'll need to combine multiple data files. Let's try a bunch of merges, and learn how merging is related to data cleaning.

### [ASGN05 - Scraping data](asgn05.html)

We're going scrap some 10-K reports from EDGAR, extract and process the text, and merge some text-based variables to Compustat.

Let's try to learn from the text something about a firm's technology, the risks it faces, and investment choices.

### [ASGN06 - Data analysis](asgn06.html)

**In the project**, we will define a question, acquire the necessary data, explore the data (for introductory analysis and to look for data issues), refine the data, and then analyze the data using (some number of) appropriate techniques. All of this will be put into a report and presentation.

In order to get use ready for the project, **this assignment** will focus on practicing that workflow and digging into the execution and interpretation of analytic models we covered in this portion of class.

### [Final project](project.html)

Check out the link above. 

